/**
 * Training Pipeline Service
 * Pipeline completo para treinamento de modelos
 * - Data preparation e validation
 * - LoRA/QLoRA training
 * - Checkpoint management
 * - Early stopping
 * - Model export e deployment
 */

import { db } from '../db/index.js';
import {
  trainingDatasets,
  trainingJobs,
  modelVersions,
  aiModels,
} from '../db/schema.js';
import { eq, and } from 'drizzle-orm';
import { withErrorHandling } from '../middleware/errorHandler.js';
import { lmstudioService } from './lmstudioService.js';
import * as fs from 'fs';
import * as path from 'path';

interface DataPreparationConfig {
  datasetId: number;
  validationSplit: number;
  shuffleData: boolean;
  maxSamples?: number;
}

interface TrainingConfig {
  modelId: number;
  datasetId: number;
  trainingType: 'lora' | 'qlora' | 'full' | 'fine-tuning';
  hyperparameters: {
    learningRate: number;
    batchSize: number;
    epochs: number;
    warmupSteps?: number;
    maxSteps?: number;
    loraRank?: number;
    loraAlpha?: number;
    loraDropout?: number;
    weightDecay?: number;
    gradientAccumulationSteps?: number;
  };
  earlyStopping: {
    enabled: boolean;
    patience: number;
    minDelta: number;
  };
  checkpointing: {
    enabled: boolean;
    interval: number; // epochs
    keepBest: number;
  };
}

interface CheckpointMetadata {
  epoch: number;
  step: number;
  loss: number;
  validationLoss: number;
  accuracy: number;
  timestamp: Date;
  path: string;
}

class TrainingPipelineService {
  private checkpointsDir = '/tmp/training-checkpoints';

  constructor() {
    // Criar diret√≥rio de checkpoints se n√£o existir
    if (!fs.existsSync(this.checkpointsDir)) {
      fs.mkdirSync(this.checkpointsDir, { recursive: true });
    }
  }

  /**
   * Preparar dados para treinamento
   */
  async prepareData(config: DataPreparationConfig): Promise<{
    trainPath: string;
    validationPath: string;
    stats: any;
  }> {
    return withErrorHandling(async () => {
      // Buscar dataset
      const [dataset] = await db
        .select()
        .from(trainingDatasets)
        .where(eq(trainingDatasets.id, config.datasetId))
        .limit(1);

      if (!dataset) {
        throw new Error('Dataset n√£o encontrado');
      }

      // Simular prepara√ß√£o de dados
      // Em produ√ß√£o, isso carregaria e processaria dados reais
      const totalSamples = dataset.recordCount || 1000;
      const trainSamples = Math.floor(totalSamples * (1 - config.validationSplit));
      const validationSamples = totalSamples - trainSamples;

      const stats = {
        totalSamples,
        trainSamples,
        validationSamples,
        datasetType: dataset.datasetType,
        format: dataset.format,
        validationSplit: config.validationSplit,
        shuffled: config.shuffleData,
        maxSamplesApplied: config.maxSamples,
      };

      // Paths simulados (em produ√ß√£o, salvar arquivos reais)
      const trainPath = `/tmp/train-${config.datasetId}.jsonl`;
      const validationPath = `/tmp/validation-${config.datasetId}.jsonl`;

      console.log(`‚úÖ Dados preparados: ${trainSamples} train, ${validationSamples} validation`);

      return {
        trainPath,
        validationPath,
        stats,
      };
    }, { name: 'prepareData' });
  }

  /**
   * Validar configura√ß√£o de treinamento
   */
  async validateTrainingConfig(config: TrainingConfig): Promise<{
    valid: boolean;
    warnings: string[];
    recommendations: string[];
  }> {
    const warnings: string[] = [];
    const recommendations: string[] = [];

    // Validar learning rate
    if (config.hyperparameters.learningRate > 0.001) {
      warnings.push('Learning rate muito alto, pode causar instabilidade');
      recommendations.push('Recomendado: learning rate entre 1e-5 e 1e-4');
    }

    // Validar batch size
    if (config.hyperparameters.batchSize > 32) {
      warnings.push('Batch size alto pode causar problemas de mem√≥ria');
    }

    // Validar LoRA config
    if (config.trainingType === 'lora' || config.trainingType === 'qlora') {
      if (!config.hyperparameters.loraRank) {
        warnings.push('LoRA rank n√£o especificado, usando default');
        recommendations.push('Recomendado: rank entre 8 e 64');
      }

      if (config.hyperparameters.loraRank && config.hyperparameters.loraRank > 128) {
        warnings.push('LoRA rank muito alto, pode aumentar custos sem ganhos');
      }
    }

    // Validar early stopping
    if (config.earlyStopping.enabled && config.earlyStopping.patience < 2) {
      warnings.push('Patience muito baixo para early stopping');
      recommendations.push('Recomendado: patience >= 3 epochs');
    }

    return {
      valid: warnings.length === 0,
      warnings,
      recommendations,
    };
  }

  /**
   * Executar pipeline completo de treinamento
   */
  async runTrainingPipeline(config: TrainingConfig): Promise<{
    jobId: number;
    status: string;
    message: string;
  }> {
    return withErrorHandling(async () => {
      // 1. Validar configura√ß√£o
      const validation = await this.validateTrainingConfig(config);
      
      if (validation.warnings.length > 0) {
        console.log('‚ö†Ô∏è  Warnings de configura√ß√£o:', validation.warnings);
      }

      // 2. Buscar modelo base
      const [model] = await db
        .select()
        .from(aiModels)
        .where(eq(aiModels.id, config.modelId))
        .limit(1);

      if (!model) {
        throw new Error('Modelo n√£o encontrado');
      }

      // 3. Preparar dados
      const dataPrep = await this.prepareData({
        datasetId: config.datasetId,
        validationSplit: 0.1,
        shuffleData: true,
      });

      console.log('üìä Dados preparados:', dataPrep.stats);

      // 4. Criar job de treinamento
      const jobResult: any = await db.insert(trainingJobs).values({
        userId: 1,
        baseModelId: config.modelId,
        datasetId: config.datasetId,
        name: `${config.trainingType.toUpperCase()} - ${model.name}`,
        description: `Pipeline training: ${config.trainingType}`,
        status: 'preparing',
        trainingType: config.trainingType,
        hyperparameters: config.hyperparameters,
        progress: '0.00',
        currentEpoch: 0,
        totalEpochs: config.hyperparameters.epochs,
        metadata: {
          dataPreparation: dataPrep.stats,
          validation,
          checkpointConfig: config.checkpointing,
          earlyStoppingConfig: config.earlyStopping,
        },
        startedAt: new Date(),
      });

      const jobId = jobResult[0]?.insertId || jobResult.insertId;

      // 5. Executar treinamento ass√≠ncrono
      this.executeTraining(jobId, config, dataPrep).catch(error => {
        console.error(`‚ùå Erro no treinamento job ${jobId}:`, error);
        this.updateJobStatus(jobId, 'failed', error.message);
      });

      return {
        jobId,
        status: 'preparing',
        message: 'Pipeline de treinamento iniciado com sucesso',
      };
    }, { name: 'runTrainingPipeline' });
  }

  /**
   * Executar treinamento (processo principal)
   */
  private async executeTraining(
    jobId: number,
    config: TrainingConfig,
    dataPrep: any
  ): Promise<void> {
    const checkpoints: CheckpointMetadata[] = [];
    let bestValidationLoss = Infinity;
    let patienceCounter = 0;

    try {
      // Fase 1: Prepara√ß√£o
      await this.updateJobStatus(jobId, 'preparing');
      await this.sleep(1000);

      // Fase 2: Treinamento
      await this.updateJobStatus(jobId, 'training');

      for (let epoch = 1; epoch <= config.hyperparameters.epochs; epoch++) {
        // Simular treinamento do epoch
        await this.sleep(3000); // 3s por epoch

        // Calcular m√©tricas
        const trainingLoss = this.calculateLoss(epoch, config.hyperparameters.epochs);
        const validationLoss = this.calculateValidationLoss(epoch, config.hyperparameters.epochs);
        const trainingAccuracy = this.calculateAccuracy(epoch, config.hyperparameters.epochs);
        const validationAccuracy = this.calculateValidationAccuracy(epoch, config.hyperparameters.epochs);

        const progress = ((epoch / config.hyperparameters.epochs) * 100).toFixed(2);

        // Atualizar progresso
        await db.update(trainingJobs)
          .set({
            currentEpoch: epoch,
            progress,
            trainingLoss: trainingLoss.toFixed(6),
            trainingAccuracy: trainingAccuracy.toFixed(2),
            validationLoss: validationLoss.toFixed(6),
            validationAccuracy: validationAccuracy.toFixed(2),
          })
          .where(eq(trainingJobs.id, jobId));

        console.log(`üìà Job ${jobId} - Epoch ${epoch}/${config.hyperparameters.epochs}`);
        console.log(`   Loss: ${trainingLoss.toFixed(4)} | Val Loss: ${validationLoss.toFixed(4)}`);
        console.log(`   Acc: ${trainingAccuracy.toFixed(2)}% | Val Acc: ${validationAccuracy.toFixed(2)}%`);

        // Checkpoint
        if (config.checkpointing.enabled && epoch % config.checkpointing.interval === 0) {
          const checkpoint = await this.saveCheckpoint(jobId, epoch, {
            loss: trainingLoss,
            validationLoss,
            accuracy: trainingAccuracy,
          });
          checkpoints.push(checkpoint);
          console.log(`üíæ Checkpoint salvo: epoch ${epoch}`);
        }

        // Early stopping
        if (config.earlyStopping.enabled) {
          if (validationLoss < bestValidationLoss - config.earlyStopping.minDelta) {
            bestValidationLoss = validationLoss;
            patienceCounter = 0;
            console.log(`‚ú® Novo melhor modelo: val_loss = ${validationLoss.toFixed(4)}`);
          } else {
            patienceCounter++;
            console.log(`‚è±Ô∏è  Patience: ${patienceCounter}/${config.earlyStopping.patience}`);

            if (patienceCounter >= config.earlyStopping.patience) {
              console.log(`üõë Early stopping ativado no epoch ${epoch}`);
              break;
            }
          }
        }
      }

      // Fase 3: Valida√ß√£o
      await this.updateJobStatus(jobId, 'validating');
      await this.sleep(2000);

      // Fase 4: Salvar modelo final
      const bestCheckpoint = this.selectBestCheckpoint(checkpoints);
      const modelVersion = await this.saveModelVersion(jobId, config.modelId, bestCheckpoint);

      // Fase 5: Completar
      await db.update(trainingJobs)
        .set({
          status: 'completed',
          progress: '100.00',
          completedAt: new Date(),
          metadata: {
            checkpoints: checkpoints.length,
            bestCheckpoint: bestCheckpoint?.path,
            earlyStoppingStopped: patienceCounter >= config.earlyStopping.patience,
            finalEpoch: checkpoints[checkpoints.length - 1]?.epoch || config.hyperparameters.epochs,
          },
        })
        .where(eq(trainingJobs.id, jobId));

      console.log(`‚úÖ Treinamento job ${jobId} COMPLETO`);

    } catch (error) {
      console.error(`‚ùå Erro no treinamento job ${jobId}:`, error);
      throw error;
    }
  }

  /**
   * Salvar checkpoint
   */
  private async saveCheckpoint(
    jobId: number,
    epoch: number,
    metrics: any
  ): Promise<CheckpointMetadata> {
    const checkpointPath = path.join(
      this.checkpointsDir,
      `job-${jobId}-epoch-${epoch}.ckpt`
    );

    // Simular salvamento de checkpoint
    // Em produ√ß√£o, salvar weights reais do modelo
    const metadata: CheckpointMetadata = {
      epoch,
      step: epoch * 100, // simulado
      loss: metrics.loss,
      validationLoss: metrics.validationLoss,
      accuracy: metrics.accuracy,
      timestamp: new Date(),
      path: checkpointPath,
    };

    return metadata;
  }

  /**
   * Selecionar melhor checkpoint
   */
  private selectBestCheckpoint(
    checkpoints: CheckpointMetadata[]
  ): CheckpointMetadata | null {
    if (checkpoints.length === 0) return null;

    return checkpoints.reduce((best, current) => {
      return current.validationLoss < best.validationLoss ? current : best;
    });
  }

  /**
   * Salvar vers√£o do modelo
   */
  private async saveModelVersion(
    jobId: number,
    baseModelId: number,
    checkpoint: CheckpointMetadata | null
  ): Promise<number> {
    const result: any = await db.insert(modelVersions).values({
      userId: 1,
      baseModelId,
      versionName: `v1.0-trained-${jobId}`,
      description: `Modelo treinado via pipeline - Job ${jobId}`,
      modelPath: checkpoint?.path || `/models/trained-${jobId}`,
      format: 'safetensors',
      trainingJobId: jobId,
      performanceMetrics: checkpoint ? {
        loss: checkpoint.loss,
        validationLoss: checkpoint.validationLoss,
        accuracy: checkpoint.accuracy,
      } : null,
      isActive: true,
      isPublic: false,
    });

    return result[0]?.insertId || result.insertId;
  }

  /**
   * Atualizar status do job
   */
  private async updateJobStatus(
    jobId: number,
    status: 'pending' | 'preparing' | 'training' | 'validating' | 'completed' | 'failed' | 'cancelled',
    errorMessage?: string
  ): Promise<void> {
    await db.update(trainingJobs)
      .set({
        status,
        errorMessage: errorMessage || null,
        ...(status === 'completed' || status === 'failed' || status === 'cancelled'
          ? { completedAt: new Date() }
          : {}),
      })
      .where(eq(trainingJobs.id, jobId));
  }

  /**
   * Calcular loss de treinamento (simulado)
   */
  private calculateLoss(currentEpoch: number, totalEpochs: number): number {
    const progress = currentEpoch / totalEpochs;
    const baseLoss = 2.5;
    const improvement = progress * 2.0;
    const noise = (Math.random() - 0.5) * 0.3;
    return Math.max(0.1, baseLoss - improvement + noise);
  }

  /**
   * Calcular validation loss (simulado)
   */
  private calculateValidationLoss(currentEpoch: number, totalEpochs: number): number {
    const trainLoss = this.calculateLoss(currentEpoch, totalEpochs);
    const overfitting = Math.random() * 0.2;
    return trainLoss + overfitting;
  }

  /**
   * Calcular accuracy (simulado)
   */
  private calculateAccuracy(currentEpoch: number, totalEpochs: number): number {
    const progress = currentEpoch / totalEpochs;
    const baseAccuracy = 40;
    const improvement = progress * 45;
    const noise = (Math.random() - 0.5) * 5;
    return Math.min(95, Math.max(35, baseAccuracy + improvement + noise));
  }

  /**
   * Calcular validation accuracy (simulado)
   */
  private calculateValidationAccuracy(currentEpoch: number, totalEpochs: number): number {
    const trainAccuracy = this.calculateAccuracy(currentEpoch, totalEpochs);
    const generalization = (Math.random() - 0.5) * 8;
    return Math.max(30, trainAccuracy + generalization);
  }

  /**
   * Helper: sleep
   */
  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Limpar checkpoints antigos
   */
  async cleanupCheckpoints(jobId: number, keepBest: number = 3): Promise<void> {
    return withErrorHandling(async () => {
      console.log(`üßπ Limpando checkpoints antigos do job ${jobId}`);
      
      // Em produ√ß√£o, deletar arquivos de checkpoint reais
      // mantendo apenas os N melhores
      
      console.log(`‚úÖ Mantidos ${keepBest} melhores checkpoints`);
    }, { name: 'cleanupCheckpoints' });
  }

  /**
   * Exportar modelo treinado
   */
  async exportModel(
    modelVersionId: number,
    format: 'gguf' | 'safetensors' | 'pytorch' | 'onnx'
  ): Promise<{
    path: string;
    size: number;
    format: string;
  }> {
    return withErrorHandling(async () => {
      const [version] = await db
        .select()
        .from(modelVersions)
        .where(eq(modelVersions.id, modelVersionId))
        .limit(1);

      if (!version) {
        throw new Error('Vers√£o do modelo n√£o encontrada');
      }

      // Simular exporta√ß√£o
      await this.sleep(1000);

      const exportPath = `/exports/model-${modelVersionId}.${format}`;
      const exportSize = Math.floor(Math.random() * 1000000000) + 500000000; // 500MB - 1.5GB

      console.log(`üì¶ Modelo exportado: ${exportPath}`);

      return {
        path: exportPath,
        size: exportSize,
        format,
      };
    }, { name: 'exportModel' });
  }
}

export const trainingPipelineService = new TrainingPipelineService();
